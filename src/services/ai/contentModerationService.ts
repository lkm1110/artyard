/**
 * ğŸ›¡ï¸ ê³ ê¸‰ ì½˜í…ì¸  ì¡°ì • AI ì‹œìŠ¤í…œ
 * ìë™í™”ëœ ì‹ ê³  ì²˜ë¦¬ ë° ë¶€ì ì ˆ ì½˜í…ì¸  íƒì§€
 */

import { supabase } from '../supabase';
import { AdvancedSpamDetectionService } from './spamDetectionService';

export interface ModerationRequest {
  contentId: string;
  contentType: 'artwork' | 'comment' | 'profile' | 'message';
  reporterId?: string;
  reportReason: string;
  reportCategory: 'spam' | 'harassment' | 'inappropriate' | 'copyright' | 'violence' | 'fake' | 'other';
  content: {
    text?: string;
    imageUrl?: string;
    metadata?: any;
  };
  priority?: 1 | 2 | 3 | 4 | 5;
}

export interface ModerationResult {
  contentId: string;
  aiDecision: 'APPROVE' | 'REVIEW' | 'REMOVE' | 'RESTRICT';
  confidence: number;
  toxicityScore: number;
  inappropriatenessScore: number;
  violationTypes: string[];
  recommendedAction: string;
  humanReviewRequired: boolean;
  estimatedReviewTime: number; // minutes
}

/**
 * ğŸ¯ ë…ì„± ì½˜í…ì¸  íƒì§€ ì—”ì§„
 */
class ToxicityDetectionEngine {
  /**
   * í…ìŠ¤íŠ¸ ë…ì„± ë¶„ì„
   */
  static analyzeToxicity(text: string): {score: number, violations: string[]} {
    const violations: string[] = [];
    let toxicityScore = 0;

    // ìš•ì„¤ ë° ë¹„ë°© íƒì§€
    const profanityPatterns = [
      // ì˜ì–´ ìš•ì„¤
      /\b(fuck|shit|damn|bitch|asshole|bastard|crap)\b/gi,
      // í˜ì˜¤ í‘œí˜„
      /\b(hate|kill|die|murder|stupid|idiot|moron|retard)\b/gi,
      // ê´´ë¡­í˜ í‘œí˜„
      /\b(loser|pathetic|worthless|disgusting)\b/gi
    ];

    profanityPatterns.forEach(pattern => {
      const matches = text.match(pattern);
      if (matches) {
        violations.push('profanity');
        toxicityScore += matches.length * 0.3;
      }
    });

    // ì„±ì  ì½˜í…ì¸  íƒì§€
    const sexualPatterns = [
      /\b(sex|porn|nude|naked|xxx|adult)\b/gi,
      /\b(breast|penis|vagina|ass|boobs)\b/gi
    ];

    sexualPatterns.forEach(pattern => {
      if (text.match(pattern)) {
        violations.push('sexual_content');
        toxicityScore += 0.4;
      }
    });

    // í­ë ¥ ê´€ë ¨ ì½˜í…ì¸ 
    const violencePatterns = [
      /\b(violence|violent|attack|assault|abuse|hurt|harm)\b/gi,
      /\b(weapon|gun|knife|bomb|explosive)\b/gi
    ];

    violencePatterns.forEach(pattern => {
      if (text.match(pattern)) {
        violations.push('violence');
        toxicityScore += 0.5;
      }
    });

    // ê°œì¸ì •ë³´ ë…¸ì¶œ
    const privacyPatterns = [
      /\b\d{3}-\d{3,4}-\d{4}\b/g, // ì „í™”ë²ˆí˜¸
      /\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b/g, // ì´ë©”ì¼
      /\b\d{4}[- ]?\d{4}[- ]?\d{4}[- ]?\d{4}\b/g // ì¹´ë“œë²ˆí˜¸ í˜•íƒœ
    ];

    privacyPatterns.forEach(pattern => {
      if (text.match(pattern)) {
        violations.push('privacy_violation');
        toxicityScore += 0.6;
      }
    });

    return {
      score: Math.min(1.0, toxicityScore),
      violations: Array.from(new Set(violations))
    };
  }

  /**
   * ì´ë¯¸ì§€ ë¶€ì ì ˆì„± ë¶„ì„ (ê¸°ë³¸ íœ´ë¦¬ìŠ¤í‹±)
   */
  static async analyzeImageContent(imageUrl: string): Promise<{score: number, violations: string[]}> {
    // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Google Vision API, AWS Rekognition ë“± ì‚¬ìš©
    // í˜„ì¬ëŠ” URL ê¸°ë°˜ ê°„ë‹¨í•œ ë¶„ì„
    
    const violations: string[] = [];
    let inappropriatenessScore = 0;

    // URLì—ì„œ ë¶€ì ì ˆí•œ í‚¤ì›Œë“œ íƒì§€
    const suspiciousKeywords = ['nude', 'sexy', 'adult', 'porn', 'xxx'];
    const urlLower = imageUrl.toLowerCase();
    
    suspiciousKeywords.forEach(keyword => {
      if (urlLower.includes(keyword)) {
        violations.push('inappropriate_image');
        inappropriatenessScore += 0.5;
      }
    });

    // íŒŒì¼ í™•ì¥ì ê²€ì¦
    const validExtensions = ['.jpg', '.jpeg', '.png', '.gif', '.webp'];
    if (!validExtensions.some(ext => urlLower.endsWith(ext))) {
      violations.push('invalid_format');
      inappropriatenessScore += 0.2;
    }

    return {
      score: Math.min(1.0, inappropriatenessScore),
      violations
    };
  }

  /**
   * ì €ì‘ê¶Œ ì¹¨í•´ íƒì§€ (ê¸°ë³¸)
   */
  static analyzeCopyrightViolation(content: any): {score: number, violations: string[]} {
    const violations: string[] = [];
    let copyrightScore = 0;

    // ì €ì‘ê¶Œ ê´€ë ¨ í‚¤ì›Œë“œ
    const copyrightIndicators = [
      'copyright', 'Â©', 'all rights reserved', 'unauthorized use',
      'watermark', 'getty images', 'shutterstock', 'stock photo'
    ];

    const text = `${content.title} ${content.description}`.toLowerCase();
    
    copyrightIndicators.forEach(indicator => {
      if (text.includes(indicator.toLowerCase())) {
        violations.push('copyright_concern');
        copyrightScore += 0.3;
      }
    });

    return {
      score: Math.min(1.0, copyrightScore),
      violations
    };
  }
}

/**
 * ğŸ¯ ìë™ ì¡°ì • ê²°ì • ì—”ì§„
 */
class AutoModerationEngine {
  /**
   * AI ê¸°ë°˜ ì¡°ì • ê²°ì •
   */
  static makeDecision(
    toxicityScore: number,
    inappropriatenessScore: number,
    spamScore: number,
    userHistory: {strikes: number, reputation: number}
  ): ModerationResult['aiDecision'] {
    
    const overallScore = Math.max(toxicityScore, inappropriatenessScore, spamScore);
    
    // ì‚¬ìš©ì ì´ë ¥ ê³ ë ¤
    const historyMultiplier = 1 + (userHistory.strikes * 0.2) - (userHistory.reputation * 0.1);
    const adjustedScore = Math.min(1.0, overallScore * historyMultiplier);

    if (adjustedScore >= 0.8) return 'REMOVE';
    if (adjustedScore >= 0.6) return 'RESTRICT';
    if (adjustedScore >= 0.3) return 'REVIEW';
    return 'APPROVE';
  }

  /**
   * ì¸ê°„ ê²€í†  í•„ìš”ì„± íŒë‹¨
   */
  static requiresHumanReview(
    aiDecision: ModerationResult['aiDecision'],
    confidence: number,
    violationTypes: string[]
  ): boolean {
    // ê³ ìœ„í—˜ ì¼€ì´ìŠ¤
    if (violationTypes.includes('violence') || violationTypes.includes('copyright_concern')) {
      return true;
    }

    // ë‚®ì€ ì‹ ë¢°ë„
    if (confidence < 0.7 && aiDecision !== 'APPROVE') {
      return true;
    }

    // ê²½ê³„ì„  ì¼€ì´ìŠ¤
    if (aiDecision === 'REVIEW') {
      return true;
    }

    return false;
  }

  /**
   * ì˜ˆìƒ ê²€í†  ì‹œê°„ ê³„ì‚°
   */
  static estimateReviewTime(
    contentType: string,
    violationTypes: string[],
    priority: number
  ): number {
    let baseTime = {
      artwork: 5,
      comment: 2,
      profile: 3,
      message: 1
    }[contentType] || 3;

    // ë³µì¡ì„±ì— ë”°ë¥¸ ì‹œê°„ ì¡°ì •
    if (violationTypes.includes('copyright_concern')) baseTime *= 3;
    if (violationTypes.includes('violence')) baseTime *= 2;
    
    // ìš°ì„ ìˆœìœ„ì— ë”°ë¥¸ ì¡°ì •
    const priorityMultiplier = Math.max(0.1, (6 - priority) / 5);
    
    return Math.round(baseTime * priorityMultiplier);
  }
}

/**
 * ğŸ¯ ì‹ ê³  ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš° ì—”ì§„
 */
class ReportProcessingEngine {
  /**
   * ì‹ ê³  ìš°ì„ ìˆœìœ„ ê³„ì‚°
   */
  static calculatePriority(request: ModerationRequest): number {
    let priority = 3; // ê¸°ë³¸ ìš°ì„ ìˆœìœ„

    // ì¹´í…Œê³ ë¦¬ë³„ ìš°ì„ ìˆœìœ„ ì¡°ì •
    const categoryPriorities = {
      violence: 5,
      harassment: 4,
      inappropriate: 3,
      spam: 2,
      copyright: 3,
      fake: 2,
      other: 1
    };

    priority = categoryPriorities[request.reportCategory] || 3;

    // ì‹ ê³ ì ì‹ ë¢°ë„ ê³ ë ¤
    // TODO: ì‹ ê³ ìì˜ ê³¼ê±° ì‹ ê³  ì •í™•ë„ ê¸°ë°˜ ì¡°ì •

    return Math.max(1, Math.min(5, priority));
  }

  /**
   * ì¤‘ë³µ ì‹ ê³  íƒì§€
   */
  static async checkDuplicateReports(contentId: string, timeWindow: number = 24): Promise<number> {
    const { data: recentReports } = await supabase
      .from('content_moderation')
      .select('id')
      .eq('content_id', contentId)
      .gte('created_at', new Date(Date.now() - timeWindow * 60 * 60 * 1000).toISOString());

    return recentReports?.length || 0;
  }

  /**
   * ì‹ ê³ ì ì‹ ë¢°ë„ í™•ì¸
   */
  static async getReporterCredibility(reporterId: string): Promise<{accuracy: number, totalReports: number}> {
    const { data: reportHistory } = await supabase
      .from('content_moderation')
      .select('moderator_decision, ai_recommendation')
      .eq('reporter_id', reporterId)
      .not('moderator_decision', 'is', null);

    if (!reportHistory || reportHistory.length === 0) {
      return { accuracy: 0.5, totalReports: 0 }; // ì¤‘ë¦½ì  ì´ˆê¸°ê°’
    }

    const accurateReports = reportHistory.filter(report => 
      (report.moderator_decision === 'removed' && report.ai_recommendation === 'REMOVE') ||
      (report.moderator_decision === 'approved' && report.ai_recommendation === 'APPROVE')
    ).length;

    return {
      accuracy: accurateReports / reportHistory.length,
      totalReports: reportHistory.length
    };
  }
}

/**
 * ğŸ¯ ë©”ì¸ ì½˜í…ì¸  ì¡°ì • ì„œë¹„ìŠ¤
 */
export class ContentModerationService {
  /**
   * ì¢…í•© ì½˜í…ì¸  ë¶„ì„ ë° ì¡°ì •
   */
  static async analyzeContent(request: ModerationRequest): Promise<ModerationResult> {
    console.log('ğŸ›¡ï¸ ì½˜í…ì¸  ì¡°ì • ë¶„ì„ ì‹œì‘:', request.contentId);

    try {
      // 1ë‹¨ê³„: ê¸°ë³¸ ë¶„ì„
      const [toxicityResult, imageResult, copyrightResult] = await Promise.all([
        request.content.text ? 
          ToxicityDetectionEngine.analyzeToxicity(request.content.text) : 
          { score: 0, violations: [] },
        request.content.imageUrl ? 
          ToxicityDetectionEngine.analyzeImageContent(request.content.imageUrl) :
          { score: 0, violations: [] },
        ToxicityDetectionEngine.analyzeCopyrightViolation(request.content)
      ]);

      // 2ë‹¨ê³„: ìŠ¤íŒ¸ ë¶„ì„
      const spamResult = request.content.text || request.content.imageUrl ? 
        await AdvancedSpamDetectionService.analyzeContent(
          request.reporterId || 'system',
          request.contentId,
          request.contentType,
          request.content
        ) : { confidence: 0 };

      // 3ë‹¨ê³„: ì‚¬ìš©ì ì´ë ¥ ì¡°íšŒ
      const userHistory = await this.getUserModerationHistory(request.contentId, request.contentType);

      // 4ë‹¨ê³„: AI ê²°ì •
      const allViolations = [
        ...toxicityResult.violations,
        ...imageResult.violations,
        ...copyrightResult.violations
      ];

      const aiDecision = AutoModerationEngine.makeDecision(
        toxicityResult.score,
        imageResult.score,
        spamResult.confidence,
        userHistory
      );

      const overallConfidence = this.calculateOverallConfidence([
        toxicityResult.score,
        imageResult.score,
        copyrightResult.score,
        spamResult.confidence
      ]);

      const humanReviewRequired = AutoModerationEngine.requiresHumanReview(
        aiDecision,
        overallConfidence,
        allViolations
      );

      const estimatedReviewTime = AutoModerationEngine.estimateReviewTime(
        request.contentType,
        allViolations,
        request.priority || 3
      );

      const result: ModerationResult = {
        contentId: request.contentId,
        aiDecision,
        confidence: overallConfidence,
        toxicityScore: toxicityResult.score,
        inappropriatenessScore: imageResult.score,
        violationTypes: allViolations,
        recommendedAction: this.generateRecommendedAction(aiDecision, allViolations),
        humanReviewRequired,
        estimatedReviewTime
      };

      // 5ë‹¨ê³„: ê²°ê³¼ ì €ì¥
      await this.saveModerationResult(request, result);

      // 6ë‹¨ê³„: ìë™ ì¡°ì¹˜ ì‹¤í–‰ (í•„ìš”ì‹œ)
      if (!humanReviewRequired && aiDecision !== 'APPROVE') {
        await this.executeAutoModeration(request, result);
      }

      console.log('âœ… ì½˜í…ì¸  ì¡°ì • ë¶„ì„ ì™„ë£Œ:', {
        decision: aiDecision,
        confidence: overallConfidence,
        humanReview: humanReviewRequired
      });

      return result;

    } catch (error) {
      console.error('ğŸ’¥ ì½˜í…ì¸  ì¡°ì • ë¶„ì„ ì‹¤íŒ¨:', error);
      
      // ì•ˆì „ì¥ì¹˜: ì¸ê°„ ê²€í† ë¡œ ì—ìŠ¤ì»¬ë ˆì´ì…˜
      return {
        contentId: request.contentId,
        aiDecision: 'REVIEW',
        confidence: 0,
        toxicityScore: 0,
        inappropriatenessScore: 0,
        violationTypes: ['analysis_failed'],
        recommendedAction: 'Escalate to human review due to analysis failure',
        humanReviewRequired: true,
        estimatedReviewTime: 30
      };
    }
  }

  /**
   * ì‹ ê³  ì ‘ìˆ˜ ë° ì²˜ë¦¬
   */
  static async processReport(request: ModerationRequest): Promise<{reportId: string, priority: number}> {
    console.log('ğŸ“ ì‹ ê³  ì ‘ìˆ˜:', request.contentId);

    try {
      // ì¤‘ë³µ ì‹ ê³  ì²´í¬
      const duplicateCount = await ReportProcessingEngine.checkDuplicateReports(request.contentId);
      
      // ì‹ ê³ ì ì‹ ë¢°ë„ í™•ì¸
      const reporterCredibility = request.reporterId ? 
        await ReportProcessingEngine.getReporterCredibility(request.reporterId) :
        { accuracy: 0.5, totalReports: 0 };

      // ìš°ì„ ìˆœìœ„ ê³„ì‚°
      const priority = ReportProcessingEngine.calculatePriority(request);

      // ì‹ ê³  ë°ì´í„° ì €ì¥
      const { data: report, error } = await supabase
        .from('content_moderation')
        .insert({
          content_id: request.contentId,
          content_type: request.contentType,
          reporter_id: request.reporterId,
          report_reason: request.reportReason,
          report_category: request.reportCategory,
          priority,
          status: 'pending'
        })
        .select('id')
        .single();

      if (error) throw error;

      // ìë™ ë¶„ì„ íŠ¸ë¦¬ê±°
      const analysisResult = await this.analyzeContent(request);
      
      // ê³ ìœ„í—˜ ì¼€ì´ìŠ¤ ì¦‰ì‹œ ì—ìŠ¤ì»¬ë ˆì´ì…˜
      if (priority >= 4 || analysisResult.toxicityScore >= 0.8) {
        await this.escalateToHighPriority(report.id);
      }

      console.log('âœ… ì‹ ê³  ì²˜ë¦¬ ì™„ë£Œ:', {
        reportId: report.id,
        priority,
        duplicates: duplicateCount,
        reporterAccuracy: reporterCredibility.accuracy
      });

      return {
        reportId: report.id,
        priority
      };

    } catch (error) {
      console.error('ğŸ’¥ ì‹ ê³  ì²˜ë¦¬ ì‹¤íŒ¨:', error);
      throw error;
    }
  }

  /**
   * ë°°ì¹˜ ì½˜í…ì¸  ìŠ¤ìº”
   */
  static async batchScanContent(
    contentType: 'artwork' | 'comment',
    limit: number = 100
  ): Promise<{scanned: number, flagged: number}> {
    console.log('ğŸ” ë°°ì¹˜ ì½˜í…ì¸  ìŠ¤ìº” ì‹œì‘:', contentType);

    let scanned = 0;
    let flagged = 0;

    try {
      const { data: contents } = await supabase
        .from(contentType === 'artwork' ? 'artworks' : 'comments')
        .select('id, title, description, created_at')
        .is('moderation_status', null) // ì•„ì§ ìŠ¤ìº”ë˜ì§€ ì•Šì€ ì½˜í…ì¸ 
        .order('created_at', { ascending: false })
        .limit(limit);

      if (!contents) return { scanned: 0, flagged: 0 };

      for (const content of contents) {
        try {
          const request: ModerationRequest = {
            contentId: content.id,
            contentType: contentType as any,
            reportReason: 'Automated batch scan',
            reportCategory: 'other',
            content: {
              text: `${content.title || ''} ${content.description || ''}`.trim()
            }
          };

          const result = await this.analyzeContent(request);
          scanned++;

          if (result.aiDecision !== 'APPROVE') {
            flagged++;
          }

          // ê²°ê³¼ë¥¼ ì½˜í…ì¸ ì— ì €ì¥
          await supabase
            .from(contentType === 'artwork' ? 'artworks' : 'comments')
            .update({
              moderation_status: result.aiDecision.toLowerCase(),
              moderation_score: result.confidence
            })
            .eq('id', content.id);

        } catch (error) {
          console.error(`ì½˜í…ì¸  ${content.id} ìŠ¤ìº” ì‹¤íŒ¨:`, error);
        }
      }

      console.log('âœ… ë°°ì¹˜ ìŠ¤ìº” ì™„ë£Œ:', { scanned, flagged });
      return { scanned, flagged };

    } catch (error) {
      console.error('ğŸ’¥ ë°°ì¹˜ ìŠ¤ìº” ì‹¤íŒ¨:', error);
      return { scanned, flagged };
    }
  }

  /**
   * í—¬í¼ í•¨ìˆ˜ë“¤
   */
  private static async getUserModerationHistory(
    contentId: string, 
    contentType: string
  ): Promise<{strikes: number, reputation: number}> {
    
    // ì½˜í…ì¸  ì†Œìœ ì ì¡°íšŒ
    let userId = null;
    if (contentType === 'artwork') {
      const { data } = await supabase
        .from('artworks')
        .select('author_id')
        .eq('id', contentId)
        .single();
      userId = data?.author_id;
    }
    // TODO: ë‹¤ë¥¸ ì½˜í…ì¸  íƒ€ì…ì— ëŒ€í•œ ì†Œìœ ì ì¡°íšŒ

    if (!userId) return { strikes: 0, reputation: 1.0 };

    const { data: moderationHistory } = await supabase
      .from('user_moderation')
      .select('action_type, severity_level')
      .eq('user_id', userId)
      .eq('is_active', true);

    const strikes = moderationHistory?.length || 0;
    const avgSeverity = moderationHistory?.reduce((sum, mod) => sum + mod.severity_level, 0) / Math.max(1, strikes);
    const reputation = Math.max(0, 1.0 - (strikes * 0.1) - (avgSeverity * 0.1));

    return { strikes, reputation };
  }

  private static calculateOverallConfidence(scores: number[]): number {
    const validScores = scores.filter(score => score > 0);
    if (validScores.length === 0) return 0.5;

    const maxScore = Math.max(...validScores);
    const avgScore = validScores.reduce((sum, score) => sum + score, 0) / validScores.length;
    
    return (maxScore + avgScore) / 2;
  }

  private static generateRecommendedAction(
    decision: ModerationResult['aiDecision'],
    violations: string[]
  ): string {
    const actions = {
      APPROVE: 'No action needed',
      REVIEW: `Human review required for: ${violations.join(', ')}`,
      RESTRICT: `Restrict visibility due to: ${violations.join(', ')}`,
      REMOVE: `Remove content immediately due to: ${violations.join(', ')}`
    };

    return actions[decision] || 'Unknown action';
  }

  private static async saveModerationResult(
    request: ModerationRequest,
    result: ModerationResult
  ): Promise<void> {
    await supabase
      .from('content_moderation')
      .update({
        ai_toxicity_score: result.toxicityScore,
        ai_inappropriateness_score: result.inappropriatenessScore,
        ai_recommendation: result.aiDecision,
        status: result.humanReviewRequired ? 'pending' : 'resolved'
      })
      .eq('content_id', request.contentId)
      .eq('content_type', request.contentType);
  }

  private static async executeAutoModeration(
    request: ModerationRequest,
    result: ModerationResult
  ): Promise<void> {
    console.log(`ğŸ”¨ ìë™ ì¡°ì¹˜ ì‹¤í–‰: ${result.aiDecision} for ${request.contentId}`);

    if (result.aiDecision === 'REMOVE') {
      // ì½˜í…ì¸  ìˆ¨ê¹€ ì²˜ë¦¬
      const table = request.contentType === 'artwork' ? 'artworks' : 'comments';
      await supabase
        .from(table)
        .update({ is_hidden: true })
        .eq('id', request.contentId);
    }

    // ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼ ë°œì†¡ (TODO: êµ¬í˜„)
    // await this.notifyUser(request.contentId, result.aiDecision);
  }

  private static async escalateToHighPriority(reportId: string): Promise<void> {
    await supabase
      .from('content_moderation')
      .update({
        priority: 5,
        status: 'escalated'
      })
      .eq('id', reportId);

    // ê´€ë¦¬ìì—ê²Œ ì¦‰ì‹œ ì•Œë¦¼ (TODO: êµ¬í˜„)
    console.log('ğŸš¨ ê³ ìœ„í—˜ ì¼€ì´ìŠ¤ ì—ìŠ¤ì»¬ë ˆì´ì…˜:', reportId);
  }
}
